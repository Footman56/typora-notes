# 一次性查 200万数据，mysql 会oom 吗？

不会 , mysql 是边读边发的

1. 扫描引擎层： 扫描数据
2. 写入缓冲区：塞进net_buffer 内存区域， 默认16KB
3. 触发发送：一旦net_buffer写满或者数据读完，就发送给客户端
4. 清空复用： 发送成功后，清空net_buffer 继续



不要一次扫描太多数据，会导致mysql buffer pool 被污染，buffer pool 存的是最热数据。根据LRU 算法（最近最少使用算法）会把热点数据挤出内存。

mysqldump 走的流式查询，配合InnoDB 的改进LRU 分离策略

InnoDB 读数据 → 先查 Buffer Pool  不在的话 → 从磁盘读入 → 放入 Buffer Pool

LRU 被分成两部分 ，young 、old 区， 热区 63%，冷区37%，通过innodb_old_blocks_pct字段控制

1. 插入策略：当从磁盘读入新页时放到“冷区头部”
2. 如果一个页在冷区且访问间隔大于1s再次被访问升级到热区   通过innodb_old_blocks_time 默认1000ms

#  慢sql怎么优化

## 全链路监控

1. 打开慢查询日志
2. 实时监控  ，利用Promentheus + grafana    

## EXPLAIN

1. 检查type字段是否为 ref、range;  警惕 index 、all 
2. Extra   Using index ：完美覆盖索引 

## SELECT * FROM sys.statement_analysis;

1. 最耗时sql   total_latency
2. 执行次数最多 
3. 锁等待最多的

## trace

线上不要长期开启

```
SELECT * 
FROM information_schema.OPTIMIZER_TRACE;
```

# 治理

1. 适当采用e s, redis 或者读操作的话强制走从库