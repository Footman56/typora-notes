```python
# 引入依赖包
import pandas as pd
import numpy as np
import torch
import torch.nn as nn
from torch.utils.data import TensorDataset, DataLoader
from sklearn.model_selection import train_test_split
import matplotlib.pyplot as plt
import os
```

```python
# -------------------------
# User config / hyperparams
# -------------------------
DATA_PATH = "/kaggle/input/linear-regression-dataset/Linear Regression - Sheet1.csv"   # <-- 替换为你的数据路径，CSV 必须包含列 x 和 y
TEST_SIZE = 0.2
RANDOM_STATE = 42
BATCH_SIZE = 32 # 分批训练集大小
LR = 1e-2 # 步长
EPOCHS = 100
DEVICE = torch.device("cuda" if torch.cuda.is_available() else "cpu")
PRINT_EVERY = 10  # 每多少个 epoch 打印一次训练信息
MODEL_SAVE_PATH = "sigmoid_two_terms_model.pt" # 保存模型地址
```

```python

# 1) 读取数据并预处理：删除空行、检查长度并按 8:2 划分
df = pd.read_csv(DATA_PATH)
print("原始行数、列数：", df.shape)

# 删除含有任意空值的行（你之前要求）
df = df.dropna(axis=0)
print("删除空行后行数、列数：", df.shape)

# 检查是否存在 x,y 列
if "X" not in df.columns or "Y" not in df.columns:
    raise ValueError("CSV 必须包含列名 'x' 和 'y'。")
```

```python
# 选取 x, y 并转换为 numpy
x = df["X"].values.astype(np.float32)
y = df["Y"].values.astype(np.float32)
```

```python
# 划分测试集和训练集 8:2来划分测试集和训练集
X_train_np, X_val_np, y_train_np, y_val_np = train_test_split(
    x, y, test_size=TEST_SIZE, random_state=RANDOM_STATE
)
```

```python
# 记录训练集的统计量以便在推理时使用相同变换
x_mean, x_std = X_train_np.mean(), X_train_np.std() if X_train_np.std() > 0 else 1.0
y_mean, y_std = y_train_np.mean(), y_train_np.std() if y_train_np.std() > 0 else 1.0

# 标准化（将 x,y 变为零均值、单位方差）——常能加速训练  
# 使用训练集的均值和标准差，来简单归一化（对回归通常有益）
X_train_np = (X_train_np - x_mean) / x_std
X_val_np = (X_val_np - x_mean) / x_std
y_train_np = (y_train_np - y_mean) / y_std
y_val_np = (y_val_np - y_mean) / y_std
```

```python
# 转为 torch tensors 并创建 DataLoader
X_train = torch.from_numpy(X_train_np).unsqueeze(1)  # shape (N,1)
X_val = torch.from_numpy(X_val_np).unsqueeze(1)
y_train = torch.from_numpy(y_train_np).unsqueeze(1)
y_val = torch.from_numpy(y_val_np).unsqueeze(1)

# 1.把训练数据和标签封装成 PyTorch 数据集 2. 让 DataLoader 能按批次读取 3.保证样本与标签的一一对应
train_ds = TensorDataset(X_train, y_train)
val_ds = TensorDataset(X_val, y_val)


# 1.将train_ds转换成可迭代的数据 2.可以批量读取数据，不需要整个读取 3.并且顺序打乱避免记住顺序
train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True)
val_loader = DataLoader(val_ds, batch_size=BATCH_SIZE, shuffle=False)
```

```
```

