# ä¸€ã€æ˜ç¡®ç³»ç»Ÿå‚æ•°

win11 ï¼Œnaviada  CUDA version 12.9 

conda æ¥ç®¡ç†è™šæ‹Ÿç¯å¢ƒ

# äºŒã€å‘½ä»¤æ“ä½œ

1. åˆ›å»ºå¹¶ä¸”æ¿€æ´»è™šæ‹Ÿç¯å¢ƒ

```
conda create -n fastai-env python=3.10 -y
conda activate fastai-env
```

2. å®‰è£… PyTorchï¼ˆæ ¹æ®ä½ çš„ NVIDIA æ˜¾å¡è‡ªåŠ¨å®‰è£… CUDAï¼‰

```

# conda install pytorch torchvision torchaudio cudatoolkit=11.8 -c pytorch -c nvidia
pip3 install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu128	
```

3. å®‰è£… fastai

```
pip install fastai
```





# ä¸‰ã€é‡åˆ°çš„é—®é¢˜

1. æœ€åˆpython=3.9 åœ¨install fastai æ—¶ éœ€è¦ä¸‹è½½ spacy ï¼Œ ä½†æ˜¯spaCy / Thinc / Blis æ— æ³•åœ¨ Windows + Python 3.9 ä¸Šç¼–è¯‘

   è§£å†³æªæ–½ï¼š å‡çº§Pythonç‰ˆæœ¬åˆ° 3.10 

2. æŠ¥é”™ä¸ºï¼š

   ```
   RuntimeError: An attempt has been made to start a new process before the current process has finished its bootstrapping phase. This probably means that you are not using fork to start your child processes and you have forgotten to use the proper idiom in the main module: if __name__ == '__main__': freeze_support() ... The "freeze_support()" line can be omitted if the program is not going to be frozen to produce an executable.
   ```

   **Windows ä¸‹è¿è¡Œ fastai çš„å¹¶è¡Œä¸‹è½½åŠŸèƒ½æ—¶ï¼Œä¼šè§¦å‘ Python multiprocessing çš„é™åˆ¶**ã€‚

   è¿™ä¸æ˜¯ fastai çš„é—®é¢˜ï¼Œè€Œæ˜¯ **Windows å¿…é¡»ä½¿ç”¨ `if __name__ == '__main__':` æ¥ä¿æŠ¤å¤šè¿›ç¨‹ä»£ç **ã€‚

3. æŠ¥é”™å¦‚ä¸‹ï¼š

   ```
   NVIDIA GeForce RTX 5060 Ti with CUDA capability sm_120 is not compatible with the current PyTorch installation. The current PyTorch install supports CUDA capabilities sm_50 sm_60 sm_61 sm_70 sm_75 sm_80 sm_86 sm_90. If you want to use the NVIDIA GeForce RTX 5060 Ti GPU with PyTorch, please check the instructions at https://pytorch.org/get-started/locally/
   ```

   5060Ti æ˜¾å¡æ˜¯æ¯”è¾ƒæ–°çš„,PyTorch ç‰ˆæœ¬ä¸æ˜¾å¡æœ‰å†²çªã€‚ éœ€è¦å®‰è£…å…¼å®¹ CUDA version 12.9  çš„pyTorch

   ```python
   pip3 install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu128	
   ```

   ç”¨äºéªŒè¯å®‰è£…æˆåŠŸçš„è„šæœ¬ä¸ºï¼š

   ```python
   import torch
   
   print("PyTorch ç‰ˆæœ¬ï¼š", torch.__version__)
   print("CUDA å¯ç”¨ï¼š", torch.cuda.is_available())
   print("æ”¯æŒçš„ CUDA ç‰ˆæœ¬ï¼š", torch.version.cuda)
   print("å½“å‰GPUè®¾å¤‡ï¼š", torch.cuda.current_device())
   print("è®¾å¤‡åç§°ï¼š", torch.cuda.get_device_name())
   
   # è¿›è¡Œä¸€ä¸ªç®€å•çš„GPUè®¡ç®—æµ‹è¯•
   if torch.cuda.is_available():
       x = torch.tensor([1.0, 2.0, 3.0]).cuda()
       y = x * 2
       print("æµ‹è¯•å¼ é‡è®¡ç®—ï¼š", y)
       print("âœ… æ­å–œï¼PyTorch å·²æˆåŠŸé…ç½®å¹¶è¿è¡Œåœ¨ä½ çš„ RTX 5060 Ti ä¸Šã€‚")
   else:
       print("âŒ CUDA ä»ä¸å¯ç”¨ï¼Œè¯·æ£€æŸ¥å®‰è£…ã€‚")
   ```

4. æƒ³è¦åœ¨python ä¸­è®¿é—®å¤–ç½‘çš„æ¥å£ï¼Œé¦–å…ˆéœ€è¦å¼€å¯ä»£ç†ä¹‹åå†æ·»åŠ ä¸‹é¢ä»£ç 

   ```python
   import os
   
   # éœ€è¦ä¿®æ”¹ä»£ç†çš„ç«¯å£ ä¸€èˆ¬clash çš„ç«¯å£ä¸º7890
   os.environ['HTTP_PROXY'] = 'http://127.0.0.1:7890'
   os.environ['HTTPS_PROXY'] = 'http://127.0.0.1:7890'
   ```

5. æŠ¥é”™ä¸ºï¼š

   ```python
   RuntimeError: Unexpected error from cudaGetDeviceCount(). Did you run some cuda functions before calling NumCudaDevices() that might have already set an error? Error 2: out of memory
   
   RuntimeError: DataLoader worker (pid(s) 16636) exited unexpectedly [W1124 14:11:39.000000000 CudaIPCTypes.cpp:16] Producer process has been terminated before all shared CUDA tensors released. See Note [Sharing CUDA tensors]
   ```

    â‘  cudaGetDeviceCount() error 2: out of memory

   è¿™ä¸ªé”™è¯¯ä¸€èˆ¬ä¸æ˜¯æ˜¾å­˜çœŸçš„ä¸è¶³ï¼Œè€Œæ˜¯ï¼š

   åœ¨ fork å‡º DataLoader worker å‰ï¼ŒGPU å·²ç»è¢«ä¸»è¿›ç¨‹åˆå§‹åŒ–ï¼Œå¯¼è‡´å­è¿›ç¨‹æ— æ³•é‡æ–°åˆå§‹åŒ– CUDAã€‚

   ğŸ‘‰ Windows DataLoader ä½¿ç”¨ `spawn`ï¼Œä¸èƒ½åœ¨ worker é‡Œé‡æ–°åˆ›å»º CUDA ä¸Šä¸‹æ–‡ã€‚

   â‘¡ DataLoader worker exited unexpectedly

   num_workers > 0 ä¼šè®©æ¯ä¸ªå­è¿›ç¨‹å°è¯•ä½¿ç”¨ GPUï¼Œä»è€Œå´©æºƒã€‚å¾ˆå¤š Windows + fastai + PyTorch ç”¨æˆ·éƒ½ä¼šé‡åˆ°è¿™ä¸ªæƒ…å†µ

â€‹		è§£å†³æ–¹å¼ä¸ºï¼š

```python
dls = DataBlock(
        blocks=(ImageBlock, CategoryBlock),
        get_items=get_image_files,
        splitter=RandomSplitter(valid_pct=0.2, seed=42),
        get_y=parent_label,
        item_tfms=[Resize(192, method='squish')]
    ).dataloaders(
        path,
        bs=16,  # â†“ æ˜¾å­˜ä¸å¤Ÿå°±æ”¹ 8 æˆ– 4
        num_workers=0  # â˜…â˜…â˜… å…³é”®ï¼šè§£å†³ä½ æ‰€æœ‰ worker GPU æŠ¥é”™
    )

    # dls.show_batch(max_n=6)

    # ====================================
    # 2. åˆ›å»º learnerï¼ˆä¸ç”¨ä¼  deviceï¼‰
    #    + ä½¿ç”¨åŠç²¾åº¦è®­ç»ƒå‡å°‘æ˜¾å­˜
    # ====================================
    learn = vision_learner(
        dls,
        resnet18,
        metrics=error_rate,
        pretrained=True,
        normalize=True
    ).to_fp16()  # â˜…â˜…â˜… å¼ºçƒˆæ¨èï¼šå‡å°‘æ˜¾å­˜ä½¿ç”¨ä¸€åŠ

    # ====================================
    # 3. æ¸…ç©º GPU æ˜¾å­˜ï¼ˆé˜²æ­¢ CUDA å·²åˆå§‹åŒ–ï¼‰
    # ====================================
    import torch

    torch.cuda.empty_cache()

    # ====================================
    # 4. å¼€å§‹è®­ç»ƒï¼ˆä¸ä¼šå†æŠ¥é”™ï¼‰
    # ====================================
    learn.fine_tune(3)

    is_bird, _, probs = learn.predict(PILImage.create('img.png'))
    print(f"This is a: {is_bird}.")
    print(f"Probability it's a bird: {probs[0]:.4f}")
```









