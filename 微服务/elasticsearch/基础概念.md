Elasticsearch 是一个**分布式**、**RESTful 风格**的***搜索***和***数据分析***引擎，可用来存储数据。

能够存储：数字、文本、地理位置、结构化数据、非结构化数据。适用于所有数据类型

# 集群（cluster）

![img](https://gcore.jsdelivr.net/gh/Footman56/imageBeds/202303311818648.png)

集群由多个节点构造，可以在elasticsearch.yaml 中通过 cluster.name 来指定集群的名称，有相同集群名称的节点会自动加入到集群中



获取整个集群的情况

```
GET _cluster/state
```

# 节点(node)

单个运行elasticsearch 的实例（进程）。一个集群可以有一个或者多个node



# 实例（节点）

每一运行的elasticsearch 实例都可以成为一个节点。运行的时候可以指定具体的配置文件，在配置文件里面可以确定是否组成集群。一台机器上可以运行多个实例；也可以多台机器上，每个机器运行一个实例。**这些实例共同存储数据。**

本质上就是一个JAVA进程

一台机器上可以运行多个Elasticsearch进程，但是**生产环境一般建议一台机器上只运 行一个Elasticsearch实例**

## 节点分类

+ master Node:主节点
+ Master eligible nodes:可以参与选举的合格节点
+ Data Node:数据节点
+ Coordinating Node:协调节点
+ 其他节点

Master eligible nodes和Master Node

每个节点启动后，默认就是一个Master eligible节点可以设置 node.master: false禁止

Master Node的职责 处理创建，删除索引等请求，负责索引的创建与删除 决定分片被分配到哪个节点
 维护并且更新Cluster State



Master-eligible节点可以参加选主流程，成为Master节点

当第一个节点启动时候，它会将自己选举成Master节点 每个节点上都保存了集群的状态，只有Master节点才能修改集群的状态信息

集群状态(Cluster State) ：维护了一个集群中，必要的信息、 所有的节点信息、所有的索引和其相关的Mapping与Setting信 息

分片的路由信息



Data Node

可以保存数据的节点，叫做Data Node，负责保存分片数据。 在数据扩展上起到了至关重要的作用，节点启动后，默认就是数据节点。可以设置node.data: false 禁止

由Master Node决定如何把分片分发到数据节点上，       通过增加数据节点可以解决数据水平扩展和解决数据单点问题



Coordinating Node

负责接受Client的请求， 将请求分发到合适的节点，最终把结果汇集到一起

每个节点默认都起到了Coordinating Node的职责





elasticsearch 7.9 之前通过这个参数来配置

| Node类型         | 配置参数    | 默认值                |
| :--------------- | :---------- | :-------------------- |
| master-eligible  | node.master | true                  |
| data             | node.data   | true                  |
| ingest           | node.ingest | true                  |
| machine learning | node.ml     | true (除了OSS发布版） |

7.9 之后就是通过

node.roles 来指定当前节点具有的角色

如果没有指定这个字段的时候，默认具有

- `master`
- `data`
- `data_content`
- `data_hot`
- `data_warm`
- `data_cold`
- `ingest`
- `ml`
- `remote_cluster_client`

如果指定这个字段的话，就是具体的角色



指定专有的master 节点

```less
node.roles: [ master ]
```

仅投票的 master-eligible 节点是参与 master但不会充当集群的主节点

```haskell
node.roles: [ data, master, voting_only ]
```

数据节点

```haskell
node.roles: [ data ]
```

Content data 节点容纳用户创建的内容。 它们启用 CRUD，搜索和聚合之类的操作。

```cobol
node.roles: [ data_content ]
```

Hot data 数据节点在输入 Elasticsearch 时会存储时间序列数据。 热层必须能够快速进行读写操作，并且需要更多的硬件资源（例如 SSD 驱动器）。

```cobol
node.roles: [ data_hot ]
```

Warm data 节点存储的索引不再定期更新，但仍在查询中。 查询量通常比索引处于热层时的频率低。 性能较低的硬件通常可用于此层中的节点。

```cobol
node.roles: [ data_warm ]
```

Cold data 节点存储只读索引，该索引的访问频率较低。 该层使用性能较低的硬件，并且可能会利用可搜索的快照索引来最大程度地减少所需的资源。

```cobol
node.roles: [ data_cold ]
```







# 索引(index)

就是数据存储的地方，类似于关系数据库中的表

与mysql 中的索引相反，将索引对应的内容作为 标识。Keyword - id 形式，正常的索引是通过key 来找内容，倒排索引是通过内容来找对应的key

倒排索引包含一个由所有文档中出现的唯一词语构成的列表，对于每一个词语而言，则为该词语所在文档的列表。如要创建倒排索引，我们首先要将每个文档的内容字段拆分成单独的词语（我们称为词汇或分词），然后创建一个包含所有唯一词汇的有序列表，再然后列出每个词语出现在哪个文档中。

索引实际存储

![image-20230206161552798](https://gcore.jsdelivr.net/gh/Footman56/imageBeds/202302061615840.png)

当我们去搜索某个关键词时，ES 首先根据它的前缀或者后缀迅速缩小关键词的在 term dictionary 中的范围

单词词典(Term Dictionary) :记录所有文档的单词，记录单词到倒排列表的 关联关系

倒排列表(Posting List)-记录了单词对应的文档结合，由倒排索引项组成

倒排索引项(Posting):

+ 文档ID 
+ 词频TF–该单词在文档中出现的次数，用于相关性评分 
+ 位置(Position)-单词在文档中分词的位置。用于短语搜索(match phrase query) 
+ 偏移(Offset)-记录单词的开始结束位置，实现高亮显示







其中一个节点可以被选为主节点，主节点当一个节点被选举成为主节点时， 它将负责管理集群范围内的所有变更，例如增加、删除索引，或者增加、删除节点等。 而主节点并不需要涉及到文档级别的变更和搜索等操作，所以当集群只拥有一个主节点的情况下，即使流量的增加它也不会成为瓶颈。 任何节点都可以成为主节点。示例集群就只有一个节点，所以它同时也成为了主节点。

集群是由一个或者多个拥有相同 `cluster.name` 配置的节点组成， 它们共同承担数据和负载的压力。当有节点加入集群中或者从集群中移除节点时，集群将会重新平均分布所有的数据。

集群内的每个实例都有自己的数据存储、日志记录，可以在启动的时候指定，也可以在配置文件中指定

![image-20230205163627954](https://gcore.jsdelivr.net/gh/Footman56/imageBeds/202302051636071.png)

# 分片

将索引数据水平切分，每一个分片都存储数据，不同的分片数据不同。查询的时候，组合多个分片的内容之后聚合到一起返回。

# 副本

为了避免单点故障，对每一个分片都可以创建任意个数的副分片（副本），每个副本的数据与主分片的数据一致，都能够读取数据。主分片负责更新数据，之后再将变化同步到所有的副本。

主分片与副本不能在同一实例内，因为都在一台机器内要坏就一起坏。

副本的数据与集群内实例数量有关系，集群内有3个节点，但是创建索引的时候设置副本为3的话，就会导致一个副本没有实例分配（主节点占用一个实例）

<img src="/Users/peilizhi/Library/Application Support/typora-user-images/image-20220719101400205.png" alt="image-20220719101400205" style="zoom:50%;" />





当数据写入 ES 时，数据将会通过 **分词** 被切分为不同的 term，ES 将 term 与其对应的文 档列表建立一种映射关系，这种结构就是 倒排索引。

# 分词

常见的分词有

+ stardard(过滤标点符号)
+ simple （过滤标点符号和数字,只剩下字母了,存储的时候不会存储标点和数字）
+ keyword （将内容作为一个整体，不做任何处理，所以这也是为什么keyword 用于精准匹配）

```
# 一个词一个词的存储
POST _analyze
{
	"analyzer":"standard",
	"text": ["中华人民共和国"]
}
```

 <img src="https://gcore.jsdelivr.net/gh/Footman56/imageBeds/202302061734334.png" alt="image-20230206154738337" style="zoom:50%;" />

```
POST _analyze
{
	"analyzer":"ik_smart",
	"text": ["中华人民共和国"]
}
```





# mapping

文档映射类似与mysql中的schema,用于定义每个字段的类型、名称、倒排索引的相关配置(Analyzer)

Mapping 可以分为动态映射、静态映射。

动态映射是指在创建索引，添加文档的时候，自动识别字段的类型

静态映射是在创建索引的时候指定字段类型

Elasticseach 自动识别的类型

| 字符串 | 匹配日期，设置为Date <br>数字的话会匹配成float或者long<br>设置为text,并增加key world |
| ------ | ------------------------------------------------------------ |
| 布尔值 | boolean                                                      |
| 浮点数 | float                                                        |
| 整数   | long                                                         |
| 对象   | Object                                                       |
| 数组   | 由第一个非空值的类型决定                                     |
| 空值   | 忽略                                                         |

```
# 获取索引的映射
GET /huochai/_mapping
```

 <img src="https://gcore.jsdelivr.net/gh/Footman56/imageBeds/202302061635332.png" alt="image-20230206163551282" style="zoom:50%;" />

## 修改字段类型

1. 新增字段

   + 如果不配置mapping 的话，就交给elasticsearch 自动识别类型

   + 在新的时候配置mapping的dynamic 字段

     |                  | true | false | strict |
     | ---------------- | ---- | ----- | ------ |
     | 文档可以被检索   | Y    | Y     | N      |
     | 字段可以被检索   | Y    | N     | N      |
     | mapping 是否更新 | Y    | N     | N      |

     ```
     # user 索引中必须包含name、address 字段，不能多字段，但是可以少字段
     PUT /user  {
     "mappings": {
     "dynamic": "strict",
     "properties": {
     "name": {
     "type": "text"
     },
     "address": {
      "type": "object",
      "dynamic": "true"
      }
      }
     } }
     ```

     

2. 对已有字段，**一旦已经有数据写入**，就不再支持修改字段定义

​	***除非重建索引***

​	i. 如果要推倒现有的映射, 你得重新建立一个静态索引 

​	ii. 然后把之前索引里的数据导入到新的索引里 

​	iii. 删除原创建的索引

​	iv. 为新索引起个别名, 为原索引名

```
# 创建静态索引
PUT user22
{
  "mappings": {
    "properties": {
      "address22":{
        "dynamic": "true",
        "properties": {
          "aa" :{
            "type": "text"
          },
          "akf":{
            "type": "text"
          }
        }
      }
      ,"name11":{
        "type": "text"
      }
    }
  }
}


# 导入数据到新索引
POST_reindex {
"source":{ "index":"user" },
"dest":{ "index":"user22" }
}

# 删除原索引
DELETE /user

# 设置别名，要先删除原索引，再指定别名
PUT/user22/_alias/user
```



## 参数配置

+ analyzer ：分词器

+ index: 控制当前字段是否被索引，默认为true。如果设置为false，该字段不可

  被搜索(不能作为查询条件)

+ index options： 控制倒排索引记录的内容
  + docs ： 记录doc id
  + freqs： 记录doc id 和term frequencies(词频)
  + positions： doc id  、term frequencies 、 term position
  + offsets： doc id 、 term frequencies 、term posistion 、character offsets

​	**text类型默认记录postions，其他默认为 docs**

+ null_value: 需要对Null值进行搜索，只有keyword类型支持设计Null_Value （可以设置为null,并且查询条件也可以为null）



# index template 

为了方便创建索引的时候使用相同的配置，不至于每次创建的时候都要设置，可以通过配置个索引模版来简化

Index Templates可以帮助你设定Mappings和Settings，并按照一定的规则，自动匹配到 新创建的索引之上

模版仅在一个索引被新创建时，才会产生作用。

修改模版不会影响已创建的索引 

你可以设定多个索引模版，这些设置会被“merge”在一起 你可以指定“order”的数值，控制“merging”的过程

```
PUT /_template/template_default 
{
 "index_patterns": ["*"],
 "order": 0,
"version": 1,
"settings": {
"number_of_shards": 1,
"number_of_replicas": 1
 }
} 
```



index Template的工作方式 当一个索引被新创建时:

1. 应用Elasticsearch 默认的settings 和mappings
2.  应用order数值低的lndex Template 中的设定
3. 应用order高的 Index Template 中的设定，之前的设定会被覆盖 应用创建索引时，
4. 用户所指定的Settings和 Mappings，并覆盖之前模版中的设定

# 配置

在elasticsearch.yaml 中的一些配置

cluster.name：当前节点所属集群名称，多个节点如果要组成同一个集群，那么集群名称一定要配置成相 同

node.name： 当前节点名称，默认值当前节点部署所在机器的主机名

path.data： 配置数据存储目录，比如索引数据等，默认值 $ES_HOME/data，生产环境下强烈建议部 署到另外的安全目录，防止ES升级导致数据被误删除。

path.logs： 配置日志存储目录，比如运行日志和集群健康信息等，默认值 $ES_HOME/logs，生产环境 下强烈建议部署到另外的安全目录，防止ES升级导致数据被误删除。

bootstrap.memory_lock： 配置ES启动时是否进行内存锁定检查，默认值true。 ES对于内存的需求比较大，一般生产环境建议配置大内存，如果内存不足，容易导致内存 交换到磁盘，严重影响ES的性能。所以默认启动时进行相应大小内存的锁定，如果无法锁 定则会启动失败。

network.host： ***配置能够访问当前节点的主机***，默认值为当前节点所在机器的本机回环地址127.0.0.1 和 [::1]，这就导致默认情况下只能通过当前节点所在主机访问当前节点。可以**配置为 0.0.0.0 ，表示所有主机均可访问。**

http.port：配置当前ES节点**对外**提供服务的http端口，默认值 9200

discovery.seed_hosts：配置参与集群节点发现过程的主机列表，说白一点就是**集群中所有节点所在的主机列表**，可 以是具体的IP地址，也可以是可解析的域名

cluster.initial_master_nodes： 配置ES集群初始化时参与master选举的节点名称列表，必须与node.name配置的一致。ES 集群首次构建完成后，应该将集群中所有节点的配置文件中的 cluster.initial_master_nodes配置项移除，重启集群或者将新节点加入某个已存在的集群 时切记不要设置该配置项。



字段配置

参数	说明
analyzer：	定义此字段索引时使用的分词方式
normalizer：	normalizer功能类似于analyzer，但是其可以使查询条件输出唯一的查询条件（可以认为其只是实现了条件小写等不会产生多个查询条件的相关操作）
boost：	定义当前字段的查询权重
coerce：	此字段控制是否尝试修复部分错误的数据格式，（比如对一个整数字段插入字符串比如"5"，此时此字符串可以被解析为数字），默认为true
copy_to：	类似于别名，不同之处参数可以将此字段内容复制到指定字段中，多个字段可以复制到同一个字段中
doc_values：	倒排索引虽然可以快速查询文档中内容，但是在进行排序或聚合操作的时候，倒排索引并不能获得文档内容，所以需要存储一份文档数据到doc_values，而此参数控制字段是否需要存储在doc_values中的开关。
dynamic：	是否开启动态映射，目前支持三个参数：true/false 开启和关闭，strict 当出现未定义的字段，抛出异常并拒绝添加文档
enabled：	此参数控制字段是否可以被索引，当被设置为false的时候表示此字段仅用来存储而无需索引，此时ES不会分析此字段内的数据，所以即使插入的非法的数据内容ES依旧允许执行
fielddata：	类似doc_values都是单独存储额外的文档数据，这样通过倒排索引获取文档内容，从而实现在排序和聚合上的功能。不同的是doc_values不支持text格式，text格式数据需要使用fielddata。此参数默认是禁止的，这是因为在第一次对字段进行排序或聚合的时候它会把这个列数据都加载到内存中，这样会带来大量的内存消耗。
eager_global_ordinals：	是否使用全局序号来进行聚合。主要在聚合分析构建hash的时候，使用序号来替代doc的值，这样在文档收集阶段根据需要收集到各个桶中，在计算结果时将序号转换为具体doc内容。但是此操作在每次查询时需要重建doc序号关系
format：	日期类型字段用来解析的日期格式
ignore_above：	当插入字段长度超过此字段设置的值后，此内容将不被索引或存储。对于数组结构字段会作用到每一个元素
ignore_malformed：	当向一个字段插入错误的数据类似时，会抛出异常并拒绝文档。但设置此参数后，对字段插入错误的数据时会忽略异常，此文档错误的数据将不被索引，但是其他字段则正常。
index_options：	控制将哪些信息添加到反向索引中
index_phrases：	主要将两个单词的组合索引到单独字段中，这样在进行精确的短语查询的时候会更有效。支持true和false参数。默认为false。此参数会使索引变大
index_prefixes：	允许对字段的前缀进行索引，此参数用来提高查询的速度
index：	控制字段是否可以被索引，被设置为false的字段无法被索引到
fields：	此参数可以为同一个字段设置不同的索引方式，但是在_source字段中只会保存一份，并不会实际增加存储。但是会增加索引大小
norms：	norms里面存储的是各种各样的归一化因子，此内容会影响到文档的得分，在不需要对字段进行打分的时候可以禁用此参数，需要注意的是对于keyword字段默认为false
null_value：	一般来说空值是无法被索引的，但是此参数允许使用指定的值替换空值，以对其进行索引
position_increment_gap：	增加近似值匹配
properties：	定义类型映射、对象字段和嵌套字段等数据
search_analyzer：	定义此字段查询时使用的分词方式
similarity：	此参数可以配置用来计算字段相似性的算法
store：	默认情况下字段内容会被索引但是并不会存储字段中的值，想获取字段中的值则需要在_source中获取对应字段的数据，当查询仅仅是尝试获取指定字段的内容的时候，可以设置此参数为true，那么系统可以直接获取此字段的内容，不再尝试获取_source中的数据。
term_vector：	术语向量的定义，存储一些术语向量，以便可以为特定文档检索它们
